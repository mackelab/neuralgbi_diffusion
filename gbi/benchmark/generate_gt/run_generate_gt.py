import pickle
import torch
import numpy as np
import time

import hydra
from omegaconf import DictConfig
from hydra.utils import get_original_cwd
from torch.distributions import MultivariateNormal
import logging

from gbi.benchmark.tasks.uniform_1d.task import UniformNoise1D
from gbi.benchmark.tasks.two_moons.task import TwoMoonsGBI
from gbi.benchmark.tasks.linear_gaussian.task import LinearGaussian
from gbi.benchmark.tasks.gaussian_mixture.task import GaussianMixture
from gbi.benchmark.generate_gt.mcmc import run_mcmc
from gbi.benchmark.generate_gt.flow import train_flow
from gbi.benchmark.generate_gt.rejection import run_rejection

log = logging.getLogger("run_benchmark_gt")


def _run_uniform_1d(x_o, cfg):
    task = UniformNoise1D(x_o=x_o, beta=cfg.task.beta)
    run_rejection(task, proposal=task.prior, config=cfg.rejection)


def _run_two_moons(x_o, cfg):
    task = TwoMoonsGBI(x_o=x_o, beta=cfg.task.beta)
    run_rejection(task, proposal=task.prior, config=cfg.rejection)


def _run_linear_gaussians(x_o, cfg):
    task = LinearGaussian(x_o=x_o, beta=cfg.task.beta)
    run_mcmc(task)
    train_flow(**cfg.flow)
    run_rejection(task, proposal="net", config=cfg.rejection)


def _run_gaussian_mixture(x_o, cfg, simulated_x, base_path):
    task = GaussianMixture(x_o=x_o.squeeze(), beta=cfg.task.beta)
    # Load GT theta to use as proposal for gaussian mixture task.
    if cfg.task.is_specified == "specified":
        # Specified GT theta exists, load
        with open(base_path + f"theta_gt_{cfg.task.is_known}.pkl", "rb") as handle:
            gt = pickle.load(handle)

        gt = gt[cfg.task.xo_index]
    else:
        # Misspecified, no GT theta. Not sure what to do here.
        print("Misspecified, no GT theta. Not sure what to do here. lol")
        # Take the average over x_os because it's generated by adding white noise to theta.
        gt = simulated_x[cfg.task.xo_index].mean(0)

    var = torch.tensor(50.0 / task.beta)
    proposal = MultivariateNormal(gt, var * torch.eye(2))
    # Run ground truth suite.
    run_rejection(task, proposal=proposal, config=cfg.rejection)


@hydra.main(version_base="1.1", config_path="config", config_name="run_gt")
def run(cfg: DictConfig) -> None:
    dir_path = get_original_cwd()
    base_path = f"{dir_path}/gbi/benchmark/tasks/{cfg.task.name}/xos/"
    with open(
        base_path + f"xo_{cfg.task.is_specified}_{cfg.task.is_known}.pkl", "rb"
    ) as handle:
        simulated_x = pickle.load(handle)
    x_o = simulated_x[cfg.task.xo_index].unsqueeze(0)

    if cfg.seed is None:
        seed = int((time.time() % 1) * 1e7)
    else:
        seed = cfg.seed
    np.savetxt("seed.txt", np.asarray([seed]))

    # Run ground truth suite.
    _ = torch.manual_seed(seed)
    _ = np.random.seed(seed=seed)

    print(f"Generating ground truth for {cfg.task.name}...")
    # Define task.
    if cfg.task.name == "uniform_1d":
        _run_uniform_1d(x_o, cfg)
    elif cfg.task.name == "two_moons":
        _run_two_moons(x_o, cfg)
    elif cfg.task.name == "linear_gaussian":
        _run_linear_gaussians(x_o, cfg)
    elif cfg.task.name == "gaussian_mixture":
        _run_gaussian_mixture(x_o, cfg, simulated_x, base_path)
    else:
        raise NotImplementedError(f"No implementation for {cfg.task.name=}")

    print("----------")


if __name__ == "__main__":
    run()
