TimeEncoder:
  input_dim: 512
  output_dim: 512
  activation_func: "ReLU"
  architecture: [1024]
  final_activation: ReLU # Sigmoid only needed for cosine similarity -> otherwise null
ThetaEncoder:
  output_dim: 128
  architecture: [256]
  activation_func: "ReLU"
  final_activation: ReLU # Sigmoid only needed for cosine similarity -> otherwise null
LatentMLP:
  architecture: [256, 156, 128]
  activation_func: "ReLU"
  final_activation: null # Sigmoid only needed for cosine similarity -> otherwise null
